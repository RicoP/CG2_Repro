<!DOCTYPE html>
<html>
<head>
    <title>Weltanschauung</title>
    
    <!-- style sheet -->
    <link rel="stylesheet" type="text/css" href="style.css">

    
    <!-- some utility libraries -->
    <script type="text/javascript" src="gl-matrix.js"></script>
    <script type="text/javascript" src="util.js"></script>
    <script type="text/javascript" src="program.js"></script>
    <script type="text/javascript" src="buffer.js"></script>
    <script type="text/javascript" src="camera.js"></script>
    <script type="text/javascript" src="scene.js"></script>
    <script type="text/javascript" src="explorer.js"></script>
    <script type="text/javascript" src="shapes.js"></script>
    <script type="text/javascript" src="light.js"></script>
    <script type="text/javascript" src="material.js"></script>
    <script type="text/javascript" src="earth-attributes.js"></script>
    <script type="text/javascript" src="transform.js"></script>
    <script type="text/javascript" src="texture.js"></script>
    <script type="text/javascript" src="simulation.js"></script>
    <script type="text/javascript" src="main.js"></script>
    
    <!-- vertex shader source code -->
    <script id="vert_shader" type="x-shader/x-vertex">
        attribute vec3 vertexPosition; 
        attribute vec3 vertexNormal;
		attribute vec2 vertexTexCoord;
		attribute vec4 modelTranslation;

        uniform mat4 modelViewMatrix;
        uniform mat4 projectionMatrix;
        uniform mat3 normalMatrix;
        
        varying vec4 ecPosition; 
        varying vec3 ecNormal;
        varying vec2 texCoord;
        
        void main() { 
        
            // transform vertex position and normal into eye coordinates 
            // for lighting calculations
            ecPosition   = modelViewMatrix * vec4(vertexPosition,1.0);
            ecNormal     = normalize(normalMatrix*vertexNormal);
            
            // set the fragment position in clip coordinates
            gl_Position  = projectionMatrix * ecPosition;
            texCoord = vertexTexCoord;
            
        }
    </script>

    <!-- fragment shader source code -->
    <script id="frag_shader" type="x-shader/x-fragment">
        precision mediump float;
		#define PI 3.141592653
        
        varying vec4  ecPosition; 
        varying vec3  ecNormal; 
		
		// texture coordinates
		varying vec2 texCoord;
		
		// textures
		uniform sampler2D daylightTexture;
		uniform sampler2D nightTexture;
		uniform sampler2D topographyTexture;
		uniform sampler2D bathymetryTexture;
		uniform sampler2D cloudTexture;
        
        // Transformation
        uniform mat4  modelViewMatrix;
        uniform mat4  projectionMatrix;

        // Ambient Light
        uniform vec3  ambientLight;

        // Material
        struct Material {
            vec3  kAmbient;
            vec3  kDiffuse;
            vec3  kSpecular;
            float shininess;
            int drawWithPhong;
        };
        uniform Material material; 

		// EarthAttributes
		struct EarthAttributes {
			float drawLightsAtNight;
			float drawClouds;
			float drawAtmosphere;
			float drawAurora;
			float time; 
		};
		uniform EarthAttributes earthAttributes;

        // Light Source Data for a directional light       
        struct DirectionalLightSource {
        
            vec3 direction; 
            vec3 color;     
            
        } ;
        uniform DirectionalLightSource light;


/* -------- RICO -------- */
vec3 mod289(vec3 x) {
  return x - floor(x * (1.0 / 289.0)) * 289.0;
}

vec2 mod289(vec2 x) {
  return x - floor(x * (1.0 / 289.0)) * 289.0;
}

vec3 permute(vec3 x) {
  return mod289(((x*34.0)+1.0)*x);
}

float snoise(vec2 v)
{
  const vec4 C = vec4(0.211324865405187,  // (3.0-sqrt(3.0))/6.0
                      0.366025403784439,  // 0.5*(sqrt(3.0)-1.0)
                     -0.577350269189626,  // -1.0 + 2.0 * C.x
                      0.024390243902439); // 1.0 / 41.0
// First corner
  vec2 i  = floor(v + dot(v, C.yy) );
  vec2 x0 = v -   i + dot(i, C.xx);

// Other corners
  vec2 i1;
  //i1.x = step( x0.y, x0.x ); // x0.x > x0.y ? 1.0 : 0.0
  //i1.y = 1.0 - i1.x;
  i1 = (x0.x > x0.y) ? vec2(1.0, 0.0) : vec2(0.0, 1.0);
  // x0 = x0 - 0.0 + 0.0 * C.xx ;
  // x1 = x0 - i1 + 1.0 * C.xx ;
  // x2 = x0 - 1.0 + 2.0 * C.xx ;
  vec4 x12 = x0.xyxy + C.xxzz;
  x12.xy -= i1;

// Permutations
  i = mod289(i); // Avoid truncation effects in permutation
  vec3 p = permute( permute( i.y + vec3(0.0, i1.y, 1.0 ))
		+ i.x + vec3(0.0, i1.x, 1.0 ));

  vec3 m = max(0.5 - vec3(dot(x0,x0), dot(x12.xy,x12.xy), dot(x12.zw,x12.zw)), 0.0);
  m = m*m ;
  m = m*m ;

// Gradients: 41 points uniformly over a line, mapped onto a diamond.
// The ring size 17*17 = 289 is close to a multiple of 41 (41*7 = 287)

  vec3 x = 2.0 * fract(p * C.www) - 1.0;
  vec3 h = abs(x) - 0.5;
  vec3 ox = floor(x + 0.5);
  vec3 a0 = x - ox;

// Normalise gradients implicitly by scaling m
// Approximation of: m *= inversesqrt( a0*a0 + h*h );
  m *= 1.79284291400159 - 0.85373472095314 * ( a0*a0 + h*h );

// Compute final noise value at P
  vec3 g;
  g.x  = a0.x  * x0.x  + h.x  * x0.y;
  g.yz = a0.yz * x12.xz + h.yz * x12.yw;
  return 130.0 * dot(m, g);
}


vec4 perlin( float time, vec2 p ) { 
	p = (p * 2.0 - 1.0) * vec2(800, 600);
	//p += mouse * 8196.0;
	p.y -= time * 596.0;
	float z = 84.0;
	float speed = 10.0;
	
	float v = snoise(p / 128. + z + 0.05 * time * speed);  p += 1017.0;
	v +=  snoise(p / 64. + z + 0.05 * time * speed) /2.;
	v +=  snoise(p / 32. + z + 0.05 * time * speed) /4.;
	v +=  snoise(p / 16. + z + 0.05 * time * speed) /8.;
	v +=  snoise(p / 8. + z + 0.05 * time * speed) /16.;
	v +=  snoise(p / 4.+ z + 0.05 * time * speed) /32.;
	v +=  snoise(p / 2.+ z + 0.05 * time * speed) /64.;
	v +=  snoise(p + z + 0.05 * time * speed) /128.;
	v = 0.1 * v + 0.5;
	
	return vec4(v*1.,0.5 + v,0.5 + v,0.5 + v);

}


vec4 mod289(vec4 x) {
	return x - floor(x * (1.0 / 289.0)) * 289.0;
}

vec4 permute(vec4 x) {
	return mod289(((x*34.0)+1.0)*x);
}

vec4 taylorInvSqrt(vec4 r) {
	return 1.79284291400159 - 0.85373472095314 * r;
}

float snoise(vec3 v) { 
	const vec2  C = vec2(1.0/6.0, 1.0/3.0) ;
	const vec4  D = vec4(0.0, 0.5, 1.0, 2.0);

	// First corner
	vec3 i  = floor(v + dot(v, C.yyy) );
	vec3 x0 =   v - i + dot(i, C.xxx) ;

	// Other corners
	vec3 g = step(x0.yzx, x0.xyz);
	vec3 l = 1.0 - g;
	vec3 i1 = min( g.xyz, l.zxy );
	vec3 i2 = max( g.xyz, l.zxy );

	//   x0 = x0 - 0.0 + 0.0 * C.xxx;
	//   x1 = x0 - i1  + 1.0 * C.xxx;
	//   x2 = x0 - i2  + 2.0 * C.xxx;
	//   x3 = x0 - 1.0 + 3.0 * C.xxx;
	vec3 x1 = x0 - i1 + C.xxx;
	vec3 x2 = x0 - i2 + C.yyy; // 2.0*C.x = 1/3 = C.y
	vec3 x3 = x0 - D.yyy;      // -1.0+3.0*C.x = -0.5 = -D.y

	// Permutations
	i = mod289(i); 
	vec4 p = permute( permute( permute( 
            i.z + vec4(0.0, i1.z, i2.z, 1.0 ))
          + i.y + vec4(0.0, i1.y, i2.y, 1.0 )) 
          + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));

	// Gradients: 7x7 points over a square, mapped onto an octahedron.
	// The ring size 17*17 = 289 is close to a multiple of 49 (49*6 = 294)
	float n_ = 0.142857142857; // 1.0/7.0
	vec3  ns = n_ * D.wyz - D.xzx;

	vec4 j = p - 49.0 * floor(p * ns.z * ns.z);  //  mod(p,7*7)

	vec4 x_ = floor(j * ns.z);
	vec4 y_ = floor(j - 7.0 * x_ );    // mod(j,N)
	
	vec4 x = x_ *ns.x + ns.yyyy;
	vec4 y = y_ *ns.x + ns.yyyy;
	vec4 h = 1.0 - abs(x) - abs(y);
	
	vec4 b0 = vec4( x.xy, y.xy );
	vec4 b1 = vec4( x.zw, y.zw );
	
	//vec4 s0 = vec4(lessThan(b0,0.0))*2.0 - 1.0;
	//vec4 s1 = vec4(lessThan(b1,0.0))*2.0 - 1.0;
	vec4 s0 = floor(b0)*2.0 + 1.0;
	vec4 s1 = floor(b1)*2.0 + 1.0;
	vec4 sh = -step(h, vec4(0.0));
	
	vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;
	vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;
	
	vec3 p0 = vec3(a0.xy,h.x);
	vec3 p1 = vec3(a0.zw,h.y);
	vec3 p2 = vec3(a1.xy,h.z);
	vec3 p3 = vec3(a1.zw,h.w);
	
	//Normalise gradients
	vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));
	p0 *= norm.x;
	p1 *= norm.y;
	p2 *= norm.z;
	p3 *= norm.w;
	
	// Mix final noise value
	vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
	m = m * m;
	//tweaked_g_toledo
	return 90.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3) ) );
}

vec3 compute(vec2 p, float time) {
	if(p.y < .5) 
		return vec3(0.0); 

	

	p *= 2.0; 
	//-mouse, bc I like it when the mouse follows (not being a smartass!)_gt
	p.x += snoise(vec3(vec2(p.x, p.y) - vec2(.5,.5), .05*time)) + (perlin(.05*time, p).y)*1.5;
	
	float r = distance(vec2(0.5, 0.5), vec2(p.x, p.y));
	
	float v = sin(r * PI * 2.0);
	//log func_g_toledo_ it just looked cool to me. I probably screwed with other stuff too.
	//v = 1.-log(2.8-v);
	//sin func_g_toledo: Uncomment for another another layer of plasma "grooves".
	v = 1.-cos(.4-v); 
	vec3 c = vec3(.9, 0.4 + 0.4 * abs(sin(time)), 0.27) * v * .7; 
	
	return c * abs(p.y); 
}


float f(float x) {
	return (sin(x * 2.0 * PI ) + 1.0) / 2.0;
}

float q(vec2 p) {
	float s = (f(p.x + 0.25)) / 5.0; 
	
	float c = smoothstep(0.9, 1.0, 1.0 - abs(p.y - s));  
	return c; 
}

vec3 comp_aurora(vec2 p, float time) {
	vec3 c1 = q( vec2(p.x, p.y / 0.4) + vec2(0.0, -0.5)) * vec3(1.0, 1.0, 1.0); 	
	vec3 c2 = q( vec2(p.x, p.y) + vec2(time, -0.2)) * vec3(.1, .1, 1.0); 	
	vec3 c3 = q( vec2(p.x, p.y / 0.4) + vec2(time / 2.0, -0.5)) * vec3(.10, 1.0, .10); 
	
	return c1+c2+c3; 
}

/* -------- RICO ENDE -------- */


        /* 
            Calculate surface color based on Blinn-Phong illumination model.
            - pos:  position of point on surface, in eye coordinates
            - n:    surface normal at pos
            - v:    direction pointing towards the viewer, in eye coordinates
        */ 
        vec3 blinnPhong(vec3 pos, vec3 n, vec3 v) {
        
            // ambient part
            vec3 ambient = material.kAmbient * ambientLight;
        
            // check viewing direction - is this back-facing?
            float ndotv = dot(n,v);
            if(ndotv<0.0)
                return vec3(0,0,0); // backface

            // vector from light to current point
            vec3 l = light.direction;
            
            // cos of angle between light and surface. 0 = light behind surface
            float ndotl = max( dot(n,-l), 0.0); 

            // diffuse contribution
            vec3 diffuse = material.kDiffuse * light.color * ndotl;
            
            // half way vector between light and viewer
            vec3 h = normalize(v-l);

            // angle between half way vector and surface normal
            float ndoth = dot(n,h);

            // specular contribution
            vec3 specular = material.kSpecular * light.color * pow(ndoth, material.shininess);
                
            // return sum of all contributions
            return ambient + diffuse + specular;
    
        }
        
        vec3 illumWorld(vec3 pos, vec3 n, vec3 v) {        	
        	// some values used for rendering
        	float drawLights 	= earthAttributes.drawLightsAtNight;
        	float height 		= texture2D(bathymetryTexture, texCoord).r;
        	float shininess 	= material.shininess;// * (1.0 - pow(height, 0.25));
        	vec3 kSpecular 		= material.kSpecular.rgb;// * (1.0 - pow(height, 0.25));
        	
        	float cloudFactor = texture2D(cloudTexture, texCoord).r;
        	
        	// colors used for rendering
        	vec3 dayColor 	= texture2D(daylightTexture, texCoord).rgb;
			vec3 nightColor = texture2D(nightTexture, texCoord).rgb * drawLights;
			
            // check viewing direction - is this back-facing?
            float ndotv = dot(n, v);
            if(ndotv < 0.0)
                return vec3(0,0,0); // backface

            // vector from light to current point
            vec3 l = light.direction;  
                  	
        	// cos of angle between light and surface. 0 = light behind surface
            float ndotl = max( dot(n, -l), 0.0);
        	
        	vec3 aPart = dayColor * ndotl + nightColor * (1.0 - ndotl) * (1.0-cloudFactor);
        	
            // ambient part
            vec3 ambient = aPart * ambientLight;
               
            // diffuse contribution
            vec3 diffuse = (dayColor - nightColor) * light.color * ndotl;
            
            // half way vector between light and viewer
            vec3 h = normalize(v - l);

            // angle between half way vector and surface normal
            float ndoth = dot(n, h);

			vec3 specular = kSpecular * light.color * pow(ndoth, shininess);
            // specular contribution
			if(height < 0.1){
           		specular = specular * 0.1;
			}
			
            // return sum of all contributions
            return ambient + diffuse + specular;
        }
		
		vec3 illumAtmosphere(vec3 pos, vec3 n, vec3 v) {
			
			// check viewing direction - is this back-facing?
            float ndotv = dot(n,v);
            if(ndotv<0.02) 
                return vec3(0,0,0); // backface

            // vector from light to current point
            vec3 l = light.direction;
            
            // cos of angle between light and surface. 0 = light behind surface
            float ndotl = max( dot(n,-l), 0.0); 
            
            vec3 atmosphere = (1.0 - dot(n, v)) * vec3(0.0,0.0,0.8);
            
            // ambient part
            vec3 ambient = (1.0 - ndotv) * atmosphere * ambientLight / 1.5;

            // diffuse contribution
            vec3 diffuse = atmosphere * light.color * ndotl;
            
            // half way vector between light and viewer
            vec3 h = normalize(v-l);

            // angle between half way vector and surface normal
            float ndoth = dot(n,h);
            


            // return sum of all contributions
			return (diffuse + ambient) * earthAttributes.drawAtmosphere;
		}
        
        vec3 illumCLouds(vec3 pos, vec3 n, vec3 v) {
        	
        	// cloudcolor
        	vec3 cloudColor = texture2D(cloudTexture, texCoord).rgb;
        	
			// check viewing direction - is this back-facing?
            float ndotv = dot(n,v);
            if(ndotv<0.02) 
                return vec3(0,0,0); // backface

            // vector from light to current point
            vec3 l = light.direction;
            
            // cos of angle between light and surface. 0 = light behind surface
            float ndotl = max( dot(n,-l), 0.0);
            
            // ambient part
            vec3 ambient = cloudColor * ambientLight;

            // diffuse contribution
            vec3 diffuse = cloudColor * light.color * ndotl;

            // return sum of all contributions
			return (diffuse + ambient);
		}
		
		float getCloudsAlpha(vec3 pos, vec3 n, vec3 v){
			
			// vector from light to current point
            vec3 l = light.direction;
            
            // cos of angle between light and surface. 0 = light behind surface
            float ndotl = max( dot(n,-l), 0.0);
            
			return (texture2D(cloudTexture, texCoord).r * ndotl);
			
		}
		
		float getAtmosphereAlpha(vec3 n, vec3 v){
			return(1.0 - dot(n, v));
		}
        
       void main() { 
        
            // normalize normal after projection
            vec3 normalEC = normalize(ecNormal);

            // do we use a perspective or an orthogonal projection matrix?
            bool usePerspective = projectionMatrix[2][3] != 0.0;
            
            // for perspective mode, the viewing direction (in eye coords) points 
            // from the vertex to the origin (0,0,0) --> use -ecPosition as direction.
            // for orthogonal mode, the viewing direction is simply (0,0,1)
            vec3 viewdirEC = usePerspective? normalize(-ecPosition.xyz) : vec3(0,0,1);

            float drawAurora    = earthAttributes.drawAurora; 
			float time          = earthAttributes.time;      
			vec3 aurora     = drawAurora != 0.0 ? compute(vec2(texCoord.x, abs(texCoord.y * 3.0)), time) * drawAurora : vec3(1.0); 


            // calculate color using Blinn-Phong function
            vec3 color;
			vec4 fragColor;
            if(material.drawWithPhong == 1){
            	color = blinnPhong( ecPosition.xyz, normalEC, viewdirEC );
				fragColor = vec4(color, 1.0);
            } else if (material.drawWithPhong == 0){
            	color = illumWorld( ecPosition.xyz, normalEC, viewdirEC );
				fragColor = vec4(color, 1.0);
            } else if (material.drawWithPhong == 2){
				float alpha = getCloudsAlpha( ecPosition.xyz, normalEC, viewdirEC );
				vec3 cloud = illumCLouds( ecPosition.xyz, normalEC, viewdirEC );
				
				fragColor = vec4(cloud * aurora.r, alpha);
			} else {
				float atmoAlpha = getAtmosphereAlpha(normalEC, viewdirEC);
				vec3 atmo = illumAtmosphere( ecPosition.xyz, normalEC, viewdirEC );
				fragColor = vec4(atmo, atmoAlpha);
			}
            gl_FragColor = fragColor;
                                
        }    
    </script>
    
</head>

<body>

<!-- layout table to place canvas and HTML form side by side -->
<table border="0">
  <tr>
    <td>
      <!-- the canvas in which to draw using WebGL -->
      <canvas id="webgl_canvas" width="600" height="600"></canvas>
    </td>
    <td class="FormCell">


<!-- Form for animation parameters -->
<div id="animForm" class="ParamForm" >
  <b>Darstellung &amp; Animation</b>
  <br><p>
    <!-- an HTML form to define the camera/projection parameters -->
    <form name="animationParameters" action="" method="post">
    	<input name="activateEarthTexture" type="checkbox" checked onclick="setEarthTexture()" >
    	Erde mit Textur anzeigen
    	<p>
        <input name="renderRing" type="checkbox" checked onclick="updateAnimationParams()" >
        &Auml;quator-Ring anzeigen
      <p>
        <input name="showLights" type="checkbox" onclick="updateAnimationParams()" >
        Nachtilichter 
      <p>
        <input name="showClouds" type="checkbox" onclick="updateAnimationParams()" >
        Wolkenschichten
      <p>
      	<input name="showAtmosphere" type="checkbox" onclick="updateAnimationParams()" >
        Atmosph&auml;re 
      <p>
        <input name="showRico1" type="checkbox" onclick="updateAnimationParams()" >
        Wolken wandern. 
     <p>
        <input name="animateSun" type="checkbox" checked onclick="startStopSunAnimation()" >
        Sonne wandert mit  
        <input name="sunSpeed" type="text" size="3" maxlength="3" value="20" 
               onchange="updateAnimationParams()"> Grad/s um den &Auml;quator<br>
      <p>
        Darzustellender Monat:
        <select name="month" size="1" onchange="updateMonth()">
            <option value="01" selected="selected">Januar</option>
            <option value="02">Februar</option>
            <option value="03">M&auml;rz</option>
            <option value="04">April</option>
            <option value="05">May</option>
            <option value="06">Juni</option>
            <option value="07">Juli</option>
            <option value="08">August</option>
            <option value="09">September</option>
            <option value="10">Oktober</option>
            <option value="11">November</option>
            <option value="12">Dezember</option>
        </select>        
    
    </form>
</div> <!-- end of container -->

<!-- form with projection parameters -->
<div id="projForm" class="ParamForm">
  <b>Kamera / Projektion</b>
  <br><p>
    <!-- an HTML form to define the camera/projection parameters -->
    <form name="cameraParameters" action="" method="post">
      <table border="0">
        <tr>
          <td>
            <input name="projection_type" type="radio" value="perspective" checked 
                    onclick="updateCameraParams()" >
          </td><td>
            Perspektivische Projektion
          </td>
        </tr>
        <tr>
          <td></td>
          <td>
            &Ouml;ffnungswinkel: <input name="fovy" type="text" size="3" maxlength="3" value="60" 
                                        onchange="updateCameraParams()"> Grad<br>
            Tiefenbereich (Z) von: <input name="znear" type="text" size="10" maxlength="10" 
                                        value="0.0001" onchange="updateCameraParams()">
            bis <input name="zfar" type="text" size="10" maxlength="10" value="1000" 
                        onchange="updateCameraParams()">
          </td>
        </tr>
        <tr>
          <td>
            <input name="projection_type" type="radio" value="orthographic" 
                    onclick="updateCameraParams()">
          </td><td>
            Orthographische Projektion
          </td>
        </tr>
        <tr>
          <td></td>
          <td>
            <table border="0">
                <tr>
                    <td>links:</td>  
                    <td><input name="left" type="text" size="10" maxlength="10" value="-1" 
                                        onchange="updateCameraParams()"></td>
                    <td>rechts:</td>  
                    <td><input name="right" type="text" size="10" maxlength="10" value="1" 
                                        onchange="updateCameraParams()"></td>
                </tr>
                <tr>
                    <td>unten:</td>  
                    <td><input name="bot" type="text" size="10" maxlength="10" value="-1" 
                                        onchange="updateCameraParams()"></td>
                    <td>oben:</td>  
                    <td><input name="top" type="text" size="10" maxlength="10" value="1" 
                                        onchange="updateCameraParams()"></td>
                </tr>
                <tr>
                    <td>vorne:</td>  
                    <td><input name="front" type="text" size="10" maxlength="10" value="0.0001" 
                                        onchange="updateCameraParams()"></td>
                    <td>hinten:</td>  
                    <td><input name="back" type="text" size="10" maxlength="10" value="1000" 
                                        onchange="updateCameraParams()"></td>
                </tr>
            </table>
          </td>
        </tr>
      </table>
    </form>
</div> <!-- end of container -->

    <!-- end of layout table cell -->
    </td>
  </tr>
</table>

<p>
Das Bildmaterial f&uuml;r diese Applikation wurde durch das Projekt <i>Earth Observatory</i> der NASA bereitgestellt. Siehe <a target="_blank" href="http://earthobservatory.nasa.gov/Features/BlueMarble/">Blue Marble: Next Generation</a>.   

      
</body>

</html>
